{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. YOLO를 이용한 사람탐지 전이학습",
   "id": "c8067d110d7b91e0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOLO11s\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 모델 로드\n",
    "model = YOLO('yolo11s.pt')\n",
    "\n",
    "# 학습 실행 - 3000장에 최적화된 간단한 설정\n",
    "results = model.train(\n",
    "    data='helmet_yolo_dataset/data.yaml',\n",
    "    epochs=150,          # 3000장이니까 조금 더 길게\n",
    "    imgsz=640,\n",
    "    batch=8,            # GPU 메모리에 따라 8~16 조정\n",
    "    patience=30,         # 30 에포크 개선 없으면 조기 종료\n",
    "    save_period=10,      # 10 에포크마다 저장\n",
    "    name='helmet_detection'  # 결과 폴더 이름\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## YOLO12s\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 모델 로드\n",
    "model = YOLO('yolo11s.pt')\n",
    "\n",
    "# 학습 실행 - 3000장에 최적화된 간단한 설정\n",
    "results = model.train(\n",
    "    data='helmet_yolo_dataset/data.yaml',\n",
    "    epochs=150,          # 3000장이니까 조금 더 길게\n",
    "    imgsz=640,\n",
    "    batch=8,            # GPU 메모리에 따라 8~16 조정\n",
    "    patience=30,         # 30 에포크 개선 없으면 조기 종료\n",
    "    save_period=10,      # 10 에포크마다 저장\n",
    "    name='helmet_detection'  # 결과 폴더 이름\n",
    ")"
   ],
   "id": "e487d10a2d42a0ae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. 객체 이미지 전처리 방식 개선",
   "id": "eea77a12e3683cb6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## 상반신crop + 컬러\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "DATA_DIR = r\"C:\\Users\\main\\Documents\\project_helmet\\DMC_Backup_cctv\\crop_데이터\\dataset_cls\"\n",
    "\n",
    "model = YOLO(\"yolo11s-cls.pt\")  # (인식 안 되면 'yolov8s-cls.pt'로 대체)\n",
    "\n",
    "results = model.train(\n",
    "    data=DATA_DIR,      # train/, val/ 포함된 루트\n",
    "    epochs=100,\n",
    "    imgsz=224,          # 분류는 224/256 권장\n",
    "    batch=16,           # VRAM 보고 조절\n",
    "    device=0 if torch.cuda.is_available() else \"cpu\",\n",
    "    workers=0,          # Windows 권장\n",
    "    name=\"helmet_cls_yolo11s\",\n",
    "    exist_ok=True,\n",
    "    patience=20,\n",
    ")"
   ],
   "id": "fefa456febe84029"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "## 상반신crop + Grayscale",
   "id": "57c4a8621d2b2cdc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Vision Transfomer(ViT) 전이 학습",
   "id": "603f4aa6150bb095"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    ViTForImageClassification,\n",
    "    ViTImageProcessor,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    TrainerCallback,\n",
    "    get_cosine_schedule_with_warmup\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import random\n",
    "\n",
    "class HelmetDataset(Dataset):\n",
    "    \"\"\"헬멧 데이터셋 클래스 (데이터 증강 포함)\"\"\"\n",
    "\n",
    "    def __init__(self, images_dir, labels_dir, processor, augment=False):\n",
    "        self.images_dir = images_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.processor = processor\n",
    "        self.augment = augment  # 데이터 증강 여부\n",
    "\n",
    "        # 이미지 파일 목록 가져오기\n",
    "        self.image_files = [f for f in os.listdir(images_dir) if f.endswith('.jpg')]\n",
    "\n",
    "        # 라벨 파일 존재 확인\n",
    "        valid_files = []\n",
    "        for img_file in self.image_files:\n",
    "            label_file = img_file.replace('.jpg', '.txt')\n",
    "            label_path = os.path.join(labels_dir, label_file)\n",
    "            if os.path.exists(label_path):\n",
    "                valid_files.append(img_file)\n",
    "\n",
    "        self.image_files = valid_files\n",
    "        print(f\"유효한 데이터: {len(self.image_files)}개\")\n",
    "        if self.augment:\n",
    "            print(\"데이터 증강 활성화: 좌우 반전 (50% 확률)\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def apply_horizontal_flip(self, image):\n",
    "        \"\"\"좌우 반전 적용 (50% 확률)\"\"\"\n",
    "        if random.random() < 0.5:\n",
    "            return cv2.flip(image, 1)  # 1은 좌우 반전\n",
    "        return image\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 이미지 로드\n",
    "        img_file = self.image_files[idx]\n",
    "        img_path = os.path.join(self.images_dir, img_file)\n",
    "\n",
    "        # OpenCV로 이미지 읽기\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            # 한글 경로 대응\n",
    "            with open(img_path, 'rb') as f:\n",
    "                img_array = np.frombuffer(f.read(), np.uint8)\n",
    "            image = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "\n",
    "        # BGR -> RGB 변환\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 데이터 증강 적용 (학습시만)\n",
    "        if self.augment:\n",
    "            image = self.apply_horizontal_flip(image)\n",
    "\n",
    "        # 라벨 로드\n",
    "        label_file = img_file.replace('.jpg', '.txt')\n",
    "        label_path = os.path.join(self.labels_dir, label_file)\n",
    "\n",
    "        with open(label_path, 'r') as f:\n",
    "            label = int(f.read().strip())\n",
    "\n",
    "        # ViTImageProcessor 적용\n",
    "        processed = self.processor(images=image, return_tensors=\"pt\")\n",
    "        pixel_values = processed['pixel_values'].squeeze(0)\n",
    "\n",
    "        return {\n",
    "            'pixel_values': pixel_values,\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"평가 메트릭 계산\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    return {'accuracy': accuracy}\n",
    "\n",
    "class LoggingCallback(TrainerCallback):\n",
    "    \"\"\"학습 로그를 JSON 파일로 저장하는 콜백\"\"\"\n",
    "\n",
    "    def __init__(self, log_file=\"training_log.json\"):\n",
    "        self.log_file = log_file\n",
    "        self.logs = []\n",
    "\n",
    "    def on_log(self, args, state, control, model=None, logs=None, **kwargs):\n",
    "        \"\"\"로그 이벤트마다 호출\"\"\"\n",
    "        if logs:\n",
    "            log_entry = {\n",
    "                'step': state.global_step,\n",
    "                'epoch': state.epoch,\n",
    "                **logs\n",
    "            }\n",
    "            self.logs.append(log_entry)\n",
    "\n",
    "            # 로그를 파일에 저장\n",
    "            with open(self.log_file, 'w') as f:\n",
    "                json.dump(self.logs, f, indent=2)\n",
    "\n",
    "def train_helmet_classifier():\n",
    "    \"\"\"개선된 헬멧 분류기 학습\"\"\"\n",
    "\n",
    "    # GPU 설정\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"사용 디바이스: {device}\")\n",
    "\n",
    "    # 데이터 경로 설정\n",
    "    base_dir = \"C:/helmet_data\"  # 경로 수정 필요시 여기서 변경\n",
    "    train_images_dir = os.path.join(base_dir, \"bbox_train_dataset\", \"images\")\n",
    "    train_labels_dir = os.path.join(base_dir, \"bbox_train_dataset\", \"labels\")\n",
    "    test_images_dir = os.path.join(base_dir, \"bbox_test_dataset\", \"images\")\n",
    "    test_labels_dir = os.path.join(base_dir, \"bbox_test_dataset\", \"labels\")\n",
    "\n",
    "    # 경로 존재 확인\n",
    "    for path in [train_images_dir, train_labels_dir, test_images_dir, test_labels_dir]:\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"경로가 존재하지 않습니다: {path}\")\n",
    "            return\n",
    "\n",
    "    # ViT 프로세서 및 모델 로드\n",
    "    print(\"ViT 모델 로딩중...\")\n",
    "    model_name = \"google/vit-base-patch16-224-in21k\"\n",
    "    processor = ViTImageProcessor.from_pretrained(model_name)\n",
    "    model = ViTForImageClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=2,  # 이진분류\n",
    "        id2label={0: \"helmet\", 1: \"no_helmet\"},\n",
    "        label2id={\"helmet\": 0, \"no_helmet\": 1}\n",
    "    )\n",
    "\n",
    "    # 모델을 GPU로 이동\n",
    "    model.to(device)\n",
    "\n",
    "    # 데이터셋 생성 (학습용은 증강 활성화, 테스트용은 비활성화)\n",
    "    print(\"데이터셋 준비중...\")\n",
    "    train_dataset = HelmetDataset(train_images_dir, train_labels_dir, processor, augment=True)\n",
    "    test_dataset = HelmetDataset(test_images_dir, test_labels_dir, processor, augment=False)\n",
    "\n",
    "    # 총 스텝 수 계산 (warmup용)\n",
    "    per_device_train_batch_size = 8\n",
    "    gradient_accumulation_steps = 2\n",
    "    num_train_epochs = 10\n",
    "    effective_batch_size = per_device_train_batch_size * gradient_accumulation_steps\n",
    "    total_steps = (len(train_dataset) // effective_batch_size) * num_train_epochs\n",
    "    warmup_steps = int(total_steps * 0.06)  # 전체의 6%\n",
    "\n",
    "    print(f\"총 스텝 수: {total_steps}\")\n",
    "    print(f\"Warmup 스텝 수: {warmup_steps}\")\n",
    "\n",
    "    # 개선된 학습 설정\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./bbox_classifier_results_improved',\n",
    "        num_train_epochs=num_train_epochs,\n",
    "\n",
    "        # 개선된 배치 설정\n",
    "        per_device_train_batch_size=per_device_train_batch_size,  # 4 → 8\n",
    "        per_device_eval_batch_size=16,  # 평가용은 더 크게\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,  # 4 → 2\n",
    "\n",
    "        # 개선된 학습률 및 스케줄러 설정\n",
    "        learning_rate=4e-5,  # 5e-5 → 4e-5\n",
    "        lr_scheduler_type=\"cosine\",  # 코사인 스케줄러 추가\n",
    "        warmup_steps=warmup_steps,\n",
    "\n",
    "        # 개선된 정규화\n",
    "        weight_decay=0.03,  # 0.01 → 0.03\n",
    "        label_smoothing_factor=0.05,  # Label smoothing 추가\n",
    "        max_grad_norm=1.0,  # Gradient clipping 추가\n",
    "\n",
    "        # 로깅 설정\n",
    "        logging_dir='./bbox_logs_improved',\n",
    "        logging_strategy=\"steps\",\n",
    "        logging_steps=50,\n",
    "        logging_first_step=True,\n",
    "\n",
    "        # 평가 설정\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=200,\n",
    "\n",
    "        # 저장 설정\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=400,\n",
    "        save_total_limit=3,  # 최근 3개만 보존 (디스크 공간 절약)\n",
    "\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "        greater_is_better=True,\n",
    "\n",
    "        # 최적화 설정\n",
    "        fp16=True,\n",
    "        gradient_checkpointing=True,\n",
    "        dataloader_pin_memory=False,\n",
    "        dataloader_num_workers=0,\n",
    "        remove_unused_columns=False,\n",
    "\n",
    "        # 리포팅 설정\n",
    "        report_to=[\"tensorboard\"],\n",
    "        run_name=\"bbox_classifier_improved_v1\",\n",
    "    )\n",
    "\n",
    "    # 로깅 콜백 생성\n",
    "    logging_callback = LoggingCallback(\"./bbox_training_progress_improved.json\")\n",
    "\n",
    "    # Trainer 생성\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[logging_callback],\n",
    "    )\n",
    "\n",
    "    # 학습 시작\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"개선된 헬멧 분류기 학습 시작!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"학습 데이터: {len(train_dataset)}개 (증강 포함)\")\n",
    "    print(f\"테스트 데이터: {len(test_dataset)}개\")\n",
    "    print(f\"Effective Batch Size: {effective_batch_size}\")\n",
    "    print(f\"총 에포크: {num_train_epochs}\")\n",
    "    print(f\"총 스텝 수: {total_steps}\")\n",
    "    print(\"\\n개선사항:\")\n",
    "    print(\"배치 사이즈: 4 → 8\")\n",
    "    print(\"학습률: 5e-5 → 4e-5 + 코사인 스케줄러\")\n",
    "    print(\"Weight decay: 0.01 → 0.03\")\n",
    "    print(\"Label smoothing: 0.05\")\n",
    "    print(\"Gradient clipping: 1.0\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # 최종 평가\n",
    "    print(\"\\n최종 평가 중...\")\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\"최종 정확도: {eval_results['eval_accuracy']:.4f}\")\n",
    "\n",
    "    # 모델 저장\n",
    "    model_save_path = \"./bbox_classifier_improved_final\"\n",
    "    trainer.save_model(model_save_path)\n",
    "    processor.save_pretrained(model_save_path)\n",
    "    print(f\"모델 저장 완료: {model_save_path}\")\n",
    "\n",
    "    # trainer_state.json도 수동으로 저장\n",
    "    trainer_state_path = \"./bbox_trainer_state_improved_final.json\"\n",
    "    with open(trainer_state_path, 'w') as f:\n",
    "        json.dump(trainer.state.__dict__, f, indent=2, default=str)\n",
    "    print(f\"학습 상태 저장 완료: {trainer_state_path}\")\n",
    "\n",
    "    # 상세 평가 (혼동 행렬 등)\n",
    "    print(\"\\n상세 평가 중...\")\n",
    "    detailed_evaluation(model, test_dataset, device)\n",
    "\n",
    "def detailed_evaluation(model, test_dataset, device):\n",
    "    \"\"\"상세 평가 수행\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"평가 중\"):\n",
    "            pixel_values = batch['pixel_values'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(pixel_values=pixel_values)\n",
    "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # 분류 리포트\n",
    "    print(\"\\n=== 분류 리포트 ===\")\n",
    "    print(classification_report(all_labels, all_predictions,\n",
    "                              target_names=['헬멧 착용', '헬멧 미착용']))\n",
    "\n",
    "    # 혼동 행렬\n",
    "    print(\"\\n=== 혼동 행렬 ===\")\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "    print(\"실제\\\\예측   헬멧착용  헬멧미착용\")\n",
    "    print(f\"헬멧착용     {cm[0,0]:6d}    {cm[0,1]:6d}\")\n",
    "    print(f\"헬멧미착용   {cm[1,0]:6d}    {cm[1,1]:6d}\")\n",
    "\n",
    "    # 정확도 계산\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    print(f\"\\n최종 정확도: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "def predict_single_image(image_path, model_path=\"./bbox_classifier_improved_final\"):\n",
    "    \"\"\"단일 이미지 예측 (개선된 모델용)\"\"\"\n",
    "    # 모델 로드\n",
    "    processor = ViTImageProcessor.from_pretrained(model_path)\n",
    "    model = ViTForImageClassification.from_pretrained(model_path)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # 이미지 로드 및 전처리\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        with open(image_path, 'rb') as f:\n",
    "            img_array = np.frombuffer(f.read(), np.uint8)\n",
    "        image = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # 예측\n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = F.softmax(outputs.logits, dim=-1)\n",
    "        predicted_class = torch.argmax(predictions, dim=-1).item()\n",
    "        confidence = predictions[0][predicted_class].item()\n",
    "\n",
    "    result = \"헬멧 착용\" if predicted_class == 0 else \"헬멧 미착용\"\n",
    "    print(f\"예측 결과: {result} (신뢰도: {confidence:.4f})\")\n",
    "\n",
    "    return predicted_class, confidence\n",
    "\n",
    "def view_training_logs():\n",
    "    \"\"\"개선된 학습 로그 확인\"\"\"\n",
    "    try:\n",
    "        with open(\"./bbox_training_progress_improved.json\", \"r\") as f:\n",
    "            logs = json.load(f)\n",
    "\n",
    "        print(\"개선된 학습 로그 요약:\")\n",
    "        print(f\"총 로그 엔트리: {len(logs)}개\")\n",
    "\n",
    "        if logs:\n",
    "            first_log = logs[0]\n",
    "            last_log = logs[-1]\n",
    "            print(f\"첫 번째 로그: Step {first_log['step']}, Epoch {first_log['epoch']}\")\n",
    "            print(f\"마지막 로그: Step {last_log['step']}, Epoch {last_log['epoch']}\")\n",
    "\n",
    "            # eval_accuracy가 있는 로그들만 필터링\n",
    "            eval_logs = [log for log in logs if 'eval_accuracy' in log]\n",
    "            if eval_logs:\n",
    "                print(f\"평가 로그: {len(eval_logs)}개\")\n",
    "                print(\"정확도 변화:\")\n",
    "                for log in eval_logs[:5]:  # 처음 5개만 출력\n",
    "                    print(f\"  Step {log['step']}: {log['eval_accuracy']:.4f}\")\n",
    "\n",
    "                # 최고 정확도 찾기\n",
    "                best_accuracy = max(eval_logs, key=lambda x: x['eval_accuracy'])\n",
    "                print(f\"최고 정확도: {best_accuracy['eval_accuracy']:.4f} (Step {best_accuracy['step']})\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"bbox_training_progress_improved.json 파일을 찾을 수 없습니다.\")\n",
    "\n",
    "def compare_with_original():\n",
    "    \"\"\"원본 결과와 개선된 결과 비교\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"성능 비교 (원본 vs 개선)\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # 원본 로그\n",
    "    try:\n",
    "        with open(\"./bbox_training_progress.json\", \"r\") as f:\n",
    "            original_logs = json.load(f)\n",
    "        original_eval_logs = [log for log in original_logs if 'eval_accuracy' in log]\n",
    "        if original_eval_logs:\n",
    "            original_best = max(original_eval_logs, key=lambda x: x['eval_accuracy'])\n",
    "            print(f\"원본 최고 정확도: {original_best['eval_accuracy']:.4f}\")\n",
    "        else:\n",
    "            print(\"원본 평가 로그를 찾을 수 없습니다.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"원본 학습 로그를 찾을 수 없습니다.\")\n",
    "\n",
    "    # 개선된 로그\n",
    "    try:\n",
    "        with open(\"./bbox_training_progress_improved.json\", \"r\") as f:\n",
    "            improved_logs = json.load(f)\n",
    "        improved_eval_logs = [log for log in improved_logs if 'eval_accuracy' in log]\n",
    "        if improved_eval_logs:\n",
    "            improved_best = max(improved_eval_logs, key=lambda x: x['eval_accuracy'])\n",
    "            print(f\"개선 최고 정확도: {improved_best['eval_accuracy']:.4f}\")\n",
    "\n",
    "            # 개선 효과 계산\n",
    "            if 'original_best' in locals():\n",
    "                improvement = improved_best['eval_accuracy'] - original_best['eval_accuracy']\n",
    "                print(f\"개선 효과: +{improvement:.4f} ({improvement*100:.2f}%p)\")\n",
    "        else:\n",
    "            print(\"개선된 평가 로그를 찾을 수 없습니다.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"개선된 학습 로그를 찾을 수 없습니다.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 개선된 학습 실행\n",
    "    train_helmet_classifier()\n",
    "\n",
    "    # 학습 완료 후 로그 확인\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    view_training_logs()\n",
    "\n",
    "    # 원본과 비교\n",
    "    compare_with_original()"
   ],
   "id": "b6aa12c580c84a22"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
